{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ilia-kuznetsov-hds/machine_learning_project/blob/main/2025_11_MLII_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8xUZ6getXIC"
   },
   "source": [
    "# Project 2 - Diagnosis coding from clinical summary using prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFXo4tbA2wAP"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "**[Double-click to write down your zID, Name and Surname]**\n",
    "\n",
    "Write your zID below and replace the placeholder “zID”, \"Name\" and \"FamilyName\" in the Jupyter Notebook name with your actual zID, name and family name. That is, instead of `zID-Project-02-Name-FamilyName.ipynb`, write your actual zID, Name and Family Name.\n",
    "\n",
    "**zID:** z5567497\n",
    "\n",
    "**Name:** Ilia\n",
    "\n",
    "**Surname:** Kuznetsov\n",
    "\n",
    "**Honour Pledge** <p>\n",
    "    \n",
    "Declaration: <p>\n",
    "    \n",
    "    \n",
    "I declare that this assessment item is **my own work**, except where acknowledged, and has not been submitted for academic credit elsewhere or previously, or produced independently of this course (e.g. for a third party such as your place of employment) and acknowledge that the assessor of this item may, for the purpose of assessing this item:\n",
    "\n",
    "1. Reproduce this assessment item and provide a copy to another member of the University; and/or\n",
    "\n",
    "2. Communicate a copy of this assessment item to a plagiarism checking service (which may then retain a copy of the assessment item on its database for the purpose of future plagiarism checking).\n",
    "\n",
    "**By writing your zID, name and surname above, you certify that you have read and agreed to the honour pledge.**\n",
    "\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGBiGx1MAs2Q"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3i9t0sLAqkr"
   },
   "source": [
    "Please write the questions as they are written in the [Word document](https://unsw-my.sharepoint.com/:w:/g/personal/z3368601_ad_unsw_edu_au/ERY2EhDgUPxAjrX0UFC_dHsBcc1e3hVtIxeWSIu-PJp5OA?e=iiAnOh) and your answers here. Create as many text or codes cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XUO91N8t-vx"
   },
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k7gE7XruFSR"
   },
   "source": [
    "Run the cell below to download the `Qwen/Qwen2.5-0.5B-Instruct` model from huggingface, and running it on CPU.\n",
    "\n",
    "DO NOT modify this cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x-wYhX78t9an"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3790737de7046978271099531a9f57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff74e7028e124173ad4cc18da81d22d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa3fcfde6c7435596027694edda6455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200de16fc8f54647a48c5dc6fc07d5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4732fde74a4663b51a3b24a8b1b80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca857876a76b47e89eade4ccacbbe122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bca32f140d45b3a09b297d1e4adb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"cpu\" # Using CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLjeUqruuqeg"
   },
   "source": [
    "## Dataset creation instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1z3omoJuvve"
   },
   "source": [
    "**Development set `patient_id`: 825, 1411, 4399, 4644, 5353**\n",
    "\n",
    "**Test set ``patient_id``: 418, 608, 2678, 3824, 3972, 4046, 4175, 4679, 4758, 5545**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5QeurEcvE4F"
   },
   "source": [
    "**Ground truth for the development set:**\n",
    "\n",
    "\n",
    "\n",
    "*   Patient_id: 825. ICD1-10-AM: G05\n",
    "*   Patient_id: 1411. ICD1-10-AM: A52\n",
    "*   Patient_id: 4399. ICD1-10-AM: K75\n",
    "*   Patient_id: 4644. ICD1-10-AM: S83\n",
    "*   Patient_id: 5353. ICD1-10-AM: L03\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAZy93sJuYkY"
   },
   "source": [
    "## Evaluation Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQK0KDBprx5H"
   },
   "source": [
    "The code in the following cell creates the pandas DataFrame containing the ground-truth labels (ICD-10-AM principal diagnosis codes) for evaluation in Question 4.\n",
    "\n",
    "DO NOT modify this cell; Run it to create the `Eval` DataFrame for Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "klo92SIVufLD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    (418,  \"C79\"),\n",
    "    (608,  \"M85\"),\n",
    "    (2678, \"C49\"),\n",
    "    (3824, \"I97\"),\n",
    "    (3972, \"A18\"),\n",
    "    (4046, \"N49\"),\n",
    "    (4175, \"K25\"),\n",
    "    (4679, \"D16\"),\n",
    "    (4758, \"J85\"),\n",
    "    (5545, \"K42\"),\n",
    "]\n",
    "\n",
    "\n",
    "Eval = pd.DataFrame(data, columns=[\n",
    "    \"patient_id\",\n",
    "    \"ICD-10-AM principal code\"\n",
    "])\n",
    "\n",
    "\n",
    "Eval[\"Model generated ICD-10-AM Code\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PG-3nyseAMk"
   },
   "source": [
    "# Question 1 – Understanding ICD-10-AM Coding and Developing Your Research\n",
    "\n",
    "- What is ICD-10-AM diagnostic coding, and what is ICD-10-AM? Write up to 300 words.\n",
    "\n",
    "- What is the principal diagnosis code (in the context of ICD-10-AM)? Write up to 100 words. You may refer to the following resource for guidance: https://ar-drg.laneprint.com.au/wp-content/uploads/2020/10/ACS-Sample.pdf\n",
    "\n",
    "- What is your research question for this project? Write up to 50 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research question: “How does the choice between structured template prompts, few-shot exemplars, and chain-of-thought prompts influence the accuracy of Qwen/Qwen2.5-0.5B-Instruct in predicting ICD-10-AM principal diagnosis codes from hospital-course summaries in the Asclepius Synthetic Clinical Notes dataset?”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRoVUNRdeHv8"
   },
   "source": [
    "# Question 2 – Understanding the Asclepius dataset:\n",
    "\n",
    "Before prompting any LLMs, it is essential to understand the data you are working with. Conduct background research on the Asclepius dataset;   \n",
    "Your answer should include, but is not limited to, the following points:\n",
    "\n",
    "- What is the original source?\n",
    "\n",
    "- How did the author create this dataset from its source?\n",
    "\n",
    "- What is the overall structure of the dataset?\n",
    "\n",
    "- What is the purpose of this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoDGTa5_eaRn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4zPe9f2enZU"
   },
   "source": [
    "# Question 3 – LLM prompt engineering\n",
    "\n",
    "Your task is to create and test a range of prompts for running inference on the designated LLM (Qwen/Qwen2.5-0.5B-Instruct) in a Google Colab environment.\n",
    "\n",
    "§ Use the hospital course summary as the input to your prompt.\n",
    "\n",
    "§ Your goal is to generate the corresponding principal diagnosis ICD-10-AM code.\n",
    "\n",
    "§ Your prompt must produce exactly one ICD-10-AM code in the model’s response for each admission.\n",
    "\n",
    "§ You must output only the ICD-10-AM category, i.e., the first three characters of the code (one letter followed by two numbers).\n",
    "\n",
    "§ You should experiment with several prompt-engineering techniques introduced in class and explore different inference hyperparameters.\n",
    "\n",
    "§ For this question, you must use only the development set when designing and refining your prompts (similar to working with a combined training–validation set).\n",
    "\n",
    "You will not be assessed on ICD-10-AM coding accuracy, but rather on the quality of your prompt-development process and your understanding of LLM inference.\n",
    "\n",
    "Keep a record of all prompts you tried as evidence of your prompt-development process. Select the five that best represent your approach and rationale, and include these in Question 3 of your Jupyter Notebook. Any additional prompts should be placed in an appendix at the end of the notebook, accompanied by comments and text cells explaining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdeb9119eb4407186357e29f1fc5852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cafec8f99949f2b8d85deb7511b6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "synthetic.csv:   0%|          | 0.00/402M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431a35df245c4b60b4012b76c9d7223e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/158114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['patient_id', 'note', 'question', 'answer', 'task'],\n",
      "        num_rows: 158114\n",
      "    })\n",
      "})\n",
      "train 158114\n",
      "Features for first split:\n",
      "{'answer': Value('string'),\n",
      " 'note': Value('string'),\n",
      " 'patient_id': Value('int64'),\n",
      " 'question': Value('string'),\n",
      " 'task': Value('string')}\n",
      "Example 0:\n",
      "{'answer': 'The healthcare team used a gradual approach to changing the '\n",
      "           \"patient's position to avoid worsening of the respiratory status \"\n",
      "           'and prevent respiratory failure.',\n",
      " 'note': 'Discharge Summary:\\n'\n",
      "         '\\n'\n",
      "         'Patient: 60-year-old male with moderate ARDS from COVID-19\\n'\n",
      "         '\\n'\n",
      "         'Hospital Course:\\n'\n",
      "         '\\n'\n",
      "         'The patient was admitted to the hospital with symptoms of fever, dry '\n",
      "         'cough, and dyspnea. During physical therapy on the acute ward, the '\n",
      "         'patient experienced coughing attacks that induced oxygen '\n",
      "         'desaturation and dyspnea with any change of position or deep '\n",
      "         'breathing. To avoid rapid deterioration and respiratory failure, a '\n",
      "         'step-by-step approach was used for position changes. The breathing '\n",
      "         'exercises were adapted to avoid prolonged coughing and oxygen '\n",
      "         'desaturation, and with close monitoring, the patient managed to '\n",
      "         'perform strength and walking exercises at a low level. Exercise '\n",
      "         'progression was low initially but increased daily until hospital '\n",
      "         'discharge to a rehabilitation clinic on day 10.\\n'\n",
      "         '\\n'\n",
      "         'Clinical Outcome:\\n'\n",
      "         '\\n'\n",
      "         'The patient was discharged on day 10 to a rehabilitation clinic '\n",
      "         'making satisfactory progress with all symptoms resolved.\\n'\n",
      "         '\\n'\n",
      "         'Follow-up:\\n'\n",
      "         '\\n'\n",
      "         'The patient will receive follow-up care at the rehabilitation '\n",
      "         'clinic, with regular monitoring of progress and further '\n",
      "         'rehabilitation exercises until full recovery. Any new symptoms or '\n",
      "         'concerns should be reported to the clinic immediately.\\n'\n",
      "         '\\n'\n",
      "         'Overall Impression:\\n'\n",
      "         '\\n'\n",
      "         'The patient responded well to treatment, and with appropriate '\n",
      "         'medical intervention, was able to overcome the difficulties faced '\n",
      "         \"during hospitalization for ARDS from COVID-19. The patient's level \"\n",
      "         'of care was of a high standard, with all necessary therapy provided '\n",
      "         'and monitoring of progress before discharge.',\n",
      " 'patient_id': 0,\n",
      " 'question': \"Can you provide a simplified paraphrase of the sentence, 'To \"\n",
      "             'avoid rapid deterioration and respiratory failure, a '\n",
      "             \"step-by-step approach was used for position changes' in the \"\n",
      "             \"patient's discharge summary?\",\n",
      " 'task': 'Paraphrasing'}\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies into the venv\n",
    "\n",
    "%pip install datasets huggingface_hub\n",
    "\n",
    "#\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "ds = load_dataset(\"starmpcc/Asclepius-Synthetic-Clinical-Notes\")\n",
    "print(ds)\n",
    "for split in ds:\n",
    "    print(split, len(ds[split]))\n",
    "print(\"Features for first split:\")\n",
    "pprint(ds[list(ds.keys())[0]].features)\n",
    "print(\"Example 0:\")\n",
    "pprint(ds[list(ds.keys())[0]][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AUkQ2RHZxq6"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jW1DbRTknTE3"
   },
   "source": [
    "© 2025 Copyright The University of New South Wales - CRICOS 00098G"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
